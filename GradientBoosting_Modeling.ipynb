{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff194698-b99b-4172-ba42-64d6e52b6719",
   "metadata": {},
   "source": [
    "# MD+ Datathon\n",
    "### Neuroncdocs Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7424c43-063d-401d-8104-dfa48b720d7e",
   "metadata": {},
   "source": [
    "# Predictive Modeling\n",
    "### Inputs\n",
    "* `user_id`: User ID. There are duplicates, but the unique values are 42283 users. No passes \n",
    "\n",
    "* `age`: User's age. Based on the statistics, there are some anomalies such as the minimum age is -196691 and the maximum age is 2018. More processing or filtering may be required. There are also quite a lot of missing values 309226. It might be worth replacing them with the mean or median value\n",
    "  \n",
    "* `sex`: User gender. There are 132135 missing values. Requires conversion from a categorical variable to a numeric variable. And it is important to check why there are 4 unique values. Gaps should be replaced with the value unknown\n",
    "  \n",
    "* `country`: User's country. There are 297985 missing values. Requires conversion from a categorical variable to a numeric variable. Gaps should be replaced with the value unknown\n",
    "  \n",
    "* `checkin_date`: Tracking date. It is important to convert to datetime format for ease of use. No passes\n",
    "  \n",
    "* `trackable_id`: ID of the event being tracked. Unique values, 264603 events. It's probably possible to delete the column, but not sure yet. No passes trackable_type: The type of event to track. 7 unique types. Explore all types. No passes ('trackable_type' --> 'trackable_name')\n",
    "  - `Condition` --> condition_keyword_groups\n",
    "  - `Symptom` --> symptom_keyword_groups\n",
    "  - `Food` --> food_keyword_groups()\n",
    "  - `Tag` --> tag_keyword_groups()\n",
    "  - `Weather` --> `icon`, `temperature_min`, `temperature_max`, `precip_intensity`, `pressure`, `humidity`\n",
    "  - `HBI`\n",
    "    \n",
    "* `trackable_name`: Name of the event being tracked, description of symptoms. 117214 unique values. There are 4 gaps\n",
    "  \n",
    "* `trackable_value`: The value of the trackable event. 15960 unique values - severity for some conditions (0-4)\n",
    "\n",
    "\n",
    "| **Domain**    | **Description** |\n",
    "|----------------|-----------------|\n",
    "| **Tags** | Self-reported contextual or psychosocial states (e.g., stress, fatigue, sleep quality). |\n",
    "| **Foods** | Dietary items categorized via hierarchical clusters (e.g., vegetables, processed foods, caffeine). |\n",
    "| **Treatments** | Medications, supplements, and therapeutic interventions (e.g., NSAIDs, SSRIs, biologics). |\n",
    "| **Weather** | Daily environmental data including maximum/minimum temperature, humidity, barometric pressure, and precipitation. |\n",
    "| **Symptoms** | Intensity scores and qualitative reports of user-experienced symptoms across multiple domains. |\n",
    "| **Conditions** | Known or self-reported disease diagnoses (e.g., Major Depressive Disorder, Rheumatoid Arthritis, POTS). |\n",
    "\n",
    "\n",
    "\n",
    "### Outputs\n",
    "\n",
    "* **Conditions:**  Predictive models estimating the probability of new or worsening disease diagnosis **within 30 days** of a given user check-in.\n",
    "* **Symptoms:**  Short-term forecasting models estimating daily symptom fluctuations or flare probability.\n",
    "\n",
    "\n",
    "| Condition | Prediction Horizon | Description |\n",
    "|------------|--------------------|--------------|\n",
    "| **Postural Orthostatic Tachycardia Syndrome (POTS)** | 30 days | Predicts initial or recurrent episodes of orthostatic intolerance (tachycardia, dizziness, lightheadedness) within the next 30 days. |\n",
    "| **Epilepsy** | 30 days | Predicts the first onset or reporting of epilepsy symptoms or diagnosis within the next 30 days. |\n",
    "| **Depression** | 30 days | Forecasts whether a user will report depressive symptoms or receive a depression-related condition within 30 days. |\n",
    "| **Anxiety** | 30 days | Estimates the likelihood of anxiety-related symptom onset or diagnosis within the next 30 days. |\n",
    "\n",
    "| Symptom | Prediction Horizon | Description |\n",
    "|----------|--------------------|--------------|\n",
    "| **Inflammatory / Rheumatoid Arthritis flares** | Next day | Predicts short-term symptom worsening (pain, swelling, stiffness) indicative of an inflammatory arthritis flare the following day. |\n",
    "\n",
    "---\n",
    "\n",
    "### Model\n",
    "\n",
    "**Light Gradient Boosting Classifier (LightGBM)**  \n",
    "A high-performance, tree-based gradient boosting algorithm optimized for structured and tabular health data.\n",
    "\n",
    "**Key Features**\n",
    "- Handles **missing values**, **categorical encoding**, and **imbalanced data** efficiently.  \n",
    "- Integrates **rolling temporal features** (7-day and 30-day symptom, treatment, and environmental aggregates).  \n",
    "- Provides **feature importance rankings** for interpretability and clinical insight.  \n",
    "- Tuned for each prediction target (condition or symptom) using class weighting, learning rate adjustment, and ensemble depth optimization.\n",
    "\n",
    "**Model configuration**\n",
    "```python\n",
    "lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40989fd-ed1f-4411-a32a-5d9e62bb7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import timedelta\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, precision_recall_curve\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cbde1-3968-4e62-aa6e-758b87a6085f",
   "metadata": {},
   "source": [
    "### Model Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e5c5b7-505b-486b-9d08-6ceacd74b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_store_results(model_name, y_true, y_prob, feature_cols, model, results_path=\"model_results.csv\", threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate model performance, extract metrics, feature importance,\n",
    "    and append results to a centralized CSV for later comparison.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Probabilistic metrics ---\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    auprc = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    # --- Binary metrics ---\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "\n",
    "    # --- Store feature importance (if available) ---\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        feature_importances = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "        top_features = \", \".join(feature_importances.head(10).index)\n",
    "    else:\n",
    "        top_features = \"N/A\"\n",
    "\n",
    "    # --- Package results ---\n",
    "    result = {\n",
    "        \"Y True\": y_true, \n",
    "        \"Y Prob\": y_prob,\n",
    "        \"Model\": model_name,\n",
    "        \"AUC\": round(auc, 3),\n",
    "        \"AUPRC\": round(auprc, 3),\n",
    "        \"Sensitivity\": round(sensitivity, 3),\n",
    "        \"Specificity\": round(specificity, 3),\n",
    "        \"Top_Features\": top_features\n",
    "    }\n",
    "\n",
    "    # --- Append to master results CSV ---\n",
    "    try:\n",
    "        existing = pd.read_csv(results_path)\n",
    "        updated = pd.concat([existing, pd.DataFrame([result])], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        updated = pd.DataFrame([result])\n",
    "\n",
    "    updated.to_csv(results_path, index=False)\n",
    "    print(f\"✅ Results saved to {results_path}\")\n",
    "    print(f\"\\n{pd.DataFrame([result])}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c7570-72e8-441b-8d31-db54c6d099e8",
   "metadata": {},
   "source": [
    "### Training + Testing Data Split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4893b5e-71ac-4b15-9493-716531de3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_balanced(\n",
    "    df,\n",
    "    label_col,\n",
    "    date_col=\"checkin_date\",\n",
    "    user_col=\"user_id\",\n",
    "    drop_cols=None,\n",
    "    pos_to_neg_ratio=3,\n",
    "    cutoff_quantile=0.8,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Temporal split (train/test) + optional random undersampling of negatives.\n",
    "    Works for any model version (Epilepsy, POTS, RA, etc.).\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort and temporal split\n",
    "    df = df.sort_values([user_col, date_col]).copy()\n",
    "    cutoff = df[date_col].quantile(cutoff_quantile)\n",
    "    train = df[df[date_col] <= cutoff].copy()\n",
    "    test  = df[df[date_col] >  cutoff].copy()\n",
    "\n",
    "    # Drop unwanted or leaky columns\n",
    "    drop_cols = drop_cols or []\n",
    "    feature_cols = [c for c in df.columns if c not in drop_cols and c != label_col]\n",
    "\n",
    "    # Undersample negatives in train set\n",
    "    pos = train[train[label_col] == 1]\n",
    "    neg = train[train[label_col] == 0]\n",
    "\n",
    "    # Sample negatives at pos_to_neg_ratio × positives (but not more than available)\n",
    "    n_neg = min(len(neg), pos_to_neg_ratio * max(len(pos), 1))\n",
    "    neg_sampled = resample(neg, replace=False, n_samples=n_neg, random_state=random_state)\n",
    "    train_bal = pd.concat([pos, neg_sampled]).sample(frac=1, random_state=random_state)\n",
    "\n",
    "    # Final matrices\n",
    "    X_train = train_bal[feature_cols]\n",
    "    y_train = train_bal[label_col].astype(int)\n",
    "    X_test  = test[feature_cols]\n",
    "    y_test  = test[label_col].astype(int)\n",
    "\n",
    "    print(\n",
    "        f\"✅ Train/Test split complete: \"\n",
    "        f\"{len(train_bal)} train ({len(pos)} pos, {n_neg} neg), {len(test)} test. \"\n",
    "        f\"Pos rate train={y_train.mean():.3f}, test={y_test.mean():.3f}\"\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, feature_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f1453-c4e6-417c-a0cc-38cf9b4da916",
   "metadata": {},
   "source": [
    "---\n",
    "# Inputs\n",
    "### Loading clusters or labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9ba2aa-0e2a-4ea2-b382-0a4bd7c59c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSVs\n",
    "conditions_df = pd.read_csv(\"conditions_clusters.csv\")\n",
    "symptoms_df = pd.read_csv(\"symptoms_clusters.csv\")\n",
    "food_df = pd.read_csv(\"foods_clusters.csv\")\n",
    "tags_df = pd.read_csv(\"tags_clusters.csv\")\n",
    "treatments_df = pd.read_csv(\"treatments_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8bcced-2d45-4aed-82a3-913d6ad52b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keyword_groups(df):\n",
    "    groups = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        term = str(row[\"term_original\"]).strip()\n",
    "        domain = str(row[\"best_domain\"]).strip()\n",
    "        if term and domain and domain.lower() != \"nan\":\n",
    "            groups[domain].append(term)\n",
    "            # Optionally, include capitalized version for robust matching\n",
    "            groups[domain].append(term.capitalize())\n",
    "    return dict(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f0d8225-59b9-48b0-a39b-eb7a42cd6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_keyword_groups = build_keyword_groups(conditions_df)\n",
    "symptom_keyword_groups = build_keyword_groups(symptoms_df)\n",
    "food_keyword_groups = build_keyword_groups(food_df)\n",
    "tag_keyword_groups = build_keyword_groups(tags_df)\n",
    "treatment_keyword_groups = build_keyword_groups(treatments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873aa7ab-5970-4414-b97a-271adc8cac22",
   "metadata": {},
   "source": [
    "---\n",
    "# Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c1222-cd09-428a-a7e1-98ece0eab5d2",
   "metadata": {},
   "source": [
    "### Predicting Disease in Individuals\n",
    "* POTS, Epilepsy, Depression, Anxiety, Inflammatory Arthritis\n",
    "* ['pots_dysautonomia', 'epilepsy_seizure', 'depression', 'anxiety', 'inflammatory_arthritis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e793bef5-9bf2-4fed-9ece-7cae17725a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ label_future_epilepsy_seizure: 1.400% positive rate\n",
      "✅ Train/Test split complete: 16420 train (3284 pos, 13136 neg), 56263 test. Pos rate train=0.200, test=0.012\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3284, number of negative: 13136\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2435\n",
      "[LightGBM] [Info] Number of data points in the train set: 16420, number of used features: 207\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200000 -> initscore=-1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "AUC  : 0.912\n",
      "AUPRC: 0.628\n",
      "Threshold~0.05: Precision=0.089  Recall=0.746\n",
      "Threshold~0.10: Precision=0.144  Recall=0.704\n",
      "Threshold~0.20: Precision=0.224  Recall=0.679\n",
      "✅ Results saved to model_results.csv\n",
      "\n",
      "                                              Y True  \\\n",
      "0  0         0\n",
      "1         0\n",
      "4         0\n",
      "5         ...   \n",
      "\n",
      "                                              Y Prob                 Model  \\\n",
      "0  [0.008834955806842968, 0.002750969433468873, 0...  Epilepsy_Future_LGBM   \n",
      "\n",
      "     AUC  AUPRC  Sensitivity  Specificity  \\\n",
      "0  0.912  0.628        0.626        0.989   \n",
      "\n",
      "                                        Top_Features  \n",
      "0  age, cond__inflammatory_arthritis, cond__migra...  \n",
      "\n",
      "Top 25 features:\n",
      " age                                      11623\n",
      "cond__inflammatory_arthritis              1528\n",
      "cond__migraine_headache                   1228\n",
      "cond__fibromyalgia                        1216\n",
      "country_top_US                            1130\n",
      "cond__anxiety                             1078\n",
      "sex_female                                1013\n",
      "cond__depression                           987\n",
      "cond__chronic_pain                         978\n",
      "cond__me_cfs                               922\n",
      "cond__inflammatory_arthritis__sum_30d      897\n",
      "cond__eds_hypermobility                    892\n",
      "country_top_GB                             855\n",
      "cond__reflux                               784\n",
      "sex_male                                   703\n",
      "cond__me_cfs__sum_30d                      656\n",
      "cond__chronic_pain__sum_30d                647\n",
      "cond__depression__sum_30d                  623\n",
      "cond__asthma                               599\n",
      "cond__anxiety__sum_30d                     592\n",
      "cond__ptsd                                 590\n",
      "cond__joint_limb_pain                      577\n",
      "cond__fnd_neurologic_other                 557\n",
      "cond__back_spine_pain                      556\n",
      "cond__inflammatory_arthritis__sum_7d       553\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: WHO WILL EVER DEVELOP THE CONDITION =========\n",
    "# (e.g., Epilepsy, POTS, Depression, etc.)\n",
    "\n",
    "# Identify all condition-specific flag columns\n",
    "target_condition = \"epilepsy_seizure\"  # <-- CHANGE THIS PER MODEL\n",
    "target_cols = [c for c in daily.columns if c.startswith(f\"cond__{target_condition}\")]\n",
    "if not target_cols:\n",
    "    raise ValueError(f\"No columns found for {target_condition}. Check your keyword mapping!\")\n",
    "\n",
    "# Determine which users ever reported the condition\n",
    "target_users = daily.loc[daily[target_cols].max(axis=1) > 0, \"user_id\"].unique()\n",
    "\n",
    "# Label every record from those users as 1 (ever developed condition), others as 0\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "daily[label_col] = daily[\"user_id\"].isin(target_users).astype(int)\n",
    "\n",
    "print(f\"✅ {label_col}: {daily[label_col].mean():.3%} positive rate\")\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "# Build a static per-user table (age/sex/country) at any row; then merge with daily\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "# Keep top 20 countries to control dimensionality\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "# Choose a cutoff date (e.g., last year as test). Adjust to your range.\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: use all engineered columns except identifiers and leakage columns\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "\n",
    "leaky_cols = target_cols + [\n",
    "    \"cond__max_severity__mean_30d\",\n",
    "    \"cond__max_severity__mean_7d\", \n",
    "    \"cond__max_severity\"\n",
    "]\n",
    "drop_cols = {\n",
    "    \"user_id\", \"checkin_date\",\n",
    "    \"has_epilepsy_today\"\n",
    "}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# Optional: scale numeric continuous columns (LightGBM doesn’t require it)\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=None,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "# Optional: show precision/recall at a few thresholds\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    # nearest threshold\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"Epilepsy_Future_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f95ca6-8e9b-4787-b0ef-1390e1716bb1",
   "metadata": {},
   "source": [
    "### Predicting Depression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d22466-30f5-4be2-afb6-71af814395d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ label_future_depression: 26.076% positive rate\n",
      "✅ Train/Test split complete: 225219 train (59438 pos, 165781 neg), 56263 test. Pos rate train=0.264, test=0.248\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59438, number of negative: 165781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2637\n",
      "[LightGBM] [Info] Number of data points in the train set: 225219, number of used features: 210\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.263912 -> initscore=-1.025734\n",
      "[LightGBM] [Info] Start training from score -1.025734\n",
      "AUC  : 0.907\n",
      "AUPRC: 0.819\n",
      "Threshold~0.05: Precision=0.371  Recall=0.957\n",
      "Threshold~0.10: Precision=0.514  Recall=0.882\n",
      "Threshold~0.20: Precision=0.671  Recall=0.809\n",
      "✅ Results saved to model_results.csv\n",
      "\n",
      "                                              Y True  \\\n",
      "0  0         0\n",
      "1         0\n",
      "4         0\n",
      "5         ...   \n",
      "\n",
      "                                              Y Prob                   Model  \\\n",
      "0  [0.0777248402043961, 0.07311859177816132, 0.11...  Depression_Future_LGBM   \n",
      "\n",
      "     AUC  AUPRC  Sensitivity  Specificity  \\\n",
      "0  0.907  0.819         0.71        0.935   \n",
      "\n",
      "                                        Top_Features  \n",
      "0  age, cond__anxiety__sum_30d, cond__inflammator...  \n",
      "\n",
      "Top 25 features:\n",
      " age                                      9769\n",
      "cond__anxiety__sum_30d                   1800\n",
      "cond__inflammatory_arthritis__sum_30d    1328\n",
      "cond__fibromyalgia__sum_30d              1172\n",
      "country_top_US                           1105\n",
      "cond__me_cfs__sum_30d                    1028\n",
      "cond__migraine_headache__sum_30d          913\n",
      "cond__chronic_pain__sum_30d               889\n",
      "cond__anxiety                             884\n",
      "country_top_GB                            869\n",
      "sex_female                                813\n",
      "cond__reflux__sum_30d                     809\n",
      "cond__anxiety__sum_7d                     776\n",
      "country_top_CA                            686\n",
      "cond__sleep_disorders__sum_30d            634\n",
      "cond__fnd_neurologic_other__sum_30d       629\n",
      "cond__inflammatory_arthritis              606\n",
      "cond__fibromyalgia                        599\n",
      "cond__back_spine_pain__sum_30d            597\n",
      "cond__ibs__sum_30d                        589\n",
      "cond__me_cfs                              587\n",
      "cond__endometriosis_gyne__sum_30d         587\n",
      "cond__inflammatory_arthritis__sum_7d      585\n",
      "sex_male                                  583\n",
      "cond__fibromyalgia__sum_7d                580\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: WHO WILL EVER DEVELOP THE CONDITION =========\n",
    "# Example here is Depression — change target_condition per script.\n",
    "\n",
    "target_condition = \"depression\"  # <-- CHANGE THIS for each model\n",
    "target_cols = [c for c in daily.columns if c.startswith(f\"cond__{target_condition}\")]\n",
    "if not target_cols:\n",
    "    raise ValueError(f\"No columns found for {target_condition}. Check your keyword mapping!\")\n",
    "\n",
    "# Determine which users ever reported this condition\n",
    "target_users = daily.loc[daily[target_cols].max(axis=1) > 0, \"user_id\"].unique()\n",
    "\n",
    "# Label every record from those users as 1 (ever developed condition), others as 0\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "daily[label_col] = daily[\"user_id\"].isin(target_users).astype(int)\n",
    "\n",
    "print(f\"✅ {label_col}: {daily[label_col].mean():.3%} positive rate\")\n",
    "\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "# Build a static per-user table (age/sex/country) at any row; then merge with daily\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "# Keep top 20 countries to control dimensionality\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "# Choose a cutoff date (e.g., last year as test). Adjust to your range.\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: use all engineered columns except identifiers and leakage columns\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "\n",
    "leaky_cols = target_cols + [\n",
    "    \"cond__max_severity__mean_30d\",\n",
    "    \"cond__max_severity__mean_7d\", \n",
    "    \"cond__max_severity\"\n",
    "]\n",
    "\n",
    "drop_cols = {\n",
    "    \"user_id\", \"checkin_date\", label_col\n",
    "}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# Optional: scale numeric continuous columns (LightGBM doesn’t require it)\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=None,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "# Optional: show precision/recall at a few thresholds\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    # nearest threshold\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"Depression_Future_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91995afa-8fad-4ebf-ab94-3f392983afd5",
   "metadata": {},
   "source": [
    "### Predicting Anxiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a91e708-5be0-4e18-847d-27b9f75347fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ label_future_anxiety: 27.095% positive rate\n",
      "✅ Train/Test split complete: 225219 train (61297 pos, 163922 neg), 56263 test. Pos rate train=0.272, test=0.266\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 61297, number of negative: 163922\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2636\n",
      "[LightGBM] [Info] Number of data points in the train set: 225219, number of used features: 210\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "AUC  : 0.894\n",
      "AUPRC: 0.817\n",
      "Threshold~0.05: Precision=0.358  Recall=0.944\n",
      "Threshold~0.10: Precision=0.404  Recall=0.927\n",
      "Threshold~0.20: Precision=0.514  Recall=0.874\n",
      "✅ Results saved to model_results.csv\n",
      "\n",
      "                                              Y True  \\\n",
      "0  0         0\n",
      "1         0\n",
      "4         0\n",
      "5         ...   \n",
      "\n",
      "                                              Y Prob                Model  \\\n",
      "0  [0.1346078307788531, 0.13268525573272946, 0.26...  Anxiety_Future_LGBM   \n",
      "\n",
      "     AUC  AUPRC  Sensitivity  Specificity  \\\n",
      "0  0.894  0.817         0.75        0.917   \n",
      "\n",
      "                                        Top_Features  \n",
      "0  age, cond__depression__sum_30d, cond__inflamma...  \n",
      "\n",
      "Top 25 features:\n",
      " age                                      9710\n",
      "cond__depression__sum_30d                1667\n",
      "cond__inflammatory_arthritis__sum_30d    1243\n",
      "cond__fibromyalgia__sum_30d              1137\n",
      "cond__me_cfs__sum_30d                    1006\n",
      "country_top_US                            998\n",
      "cond__chronic_pain__sum_30d               935\n",
      "cond__depression                          872\n",
      "country_top_GB                            868\n",
      "cond__migraine_headache__sum_30d          857\n",
      "cond__reflux__sum_30d                     807\n",
      "cond__depression__sum_7d                  703\n",
      "cond__inflammatory_arthritis              686\n",
      "sex_female                                683\n",
      "cond__ibs__sum_30d                        627\n",
      "sex_other                                 622\n",
      "cond__fibromyalgia                        617\n",
      "cond__joint_limb_pain__sum_30d            587\n",
      "cond__fnd_neurologic_other__sum_30d       582\n",
      "sex_male                                  576\n",
      "cond__sleep_disorders__sum_30d            571\n",
      "cond__chronic_pain                        569\n",
      "country_top_CA                            567\n",
      "cond__fibromyalgia__sum_7d                565\n",
      "cond__me_cfs                              564\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: WHO WILL EVER DEVELOP THE CONDITION =========\n",
    "# Example here is Depression — change target_condition per script.\n",
    "\n",
    "target_condition = \"anxiety\"  # <-- CHANGE THIS for each model\n",
    "target_cols = [c for c in daily.columns if c.startswith(f\"cond__{target_condition}\")]\n",
    "if not target_cols:\n",
    "    raise ValueError(f\"No columns found for {target_condition}. Check your keyword mapping!\")\n",
    "\n",
    "# Determine which users ever reported this condition\n",
    "target_users = daily.loc[daily[target_cols].max(axis=1) > 0, \"user_id\"].unique()\n",
    "\n",
    "# Label every record from those users as 1 (ever developed condition), others as 0\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "daily[label_col] = daily[\"user_id\"].isin(target_users).astype(int)\n",
    "\n",
    "print(f\"✅ {label_col}: {daily[label_col].mean():.3%} positive rate\")\n",
    "\n",
    "\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "# Build a static per-user table (age/sex/country) at any row; then merge with daily\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "# Keep top 20 countries to control dimensionality\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "# Choose a cutoff date (e.g., last year as test). Adjust to your range.\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: use all engineered columns except identifiers and leakage columns\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "\n",
    "leaky_cols = target_cols + [\n",
    "    \"cond__max_severity__mean_30d\",\n",
    "    \"cond__max_severity__mean_7d\", \n",
    "    \"cond__max_severity\"\n",
    "]\n",
    "drop_cols = {\n",
    "    \"user_id\", \"checkin_date\", label_col\n",
    "}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# Optional: scale numeric continuous columns (LightGBM doesn’t require it)\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "# Optional: show precision/recall at a few thresholds\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    # nearest threshold\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"Anxiety_Future_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60d7bc-b9df-49bf-8eb0-479962412db3",
   "metadata": {},
   "source": [
    "### Predicting POTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "979da312-b4d8-4545-91db-db59a1b312ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ label_future_pots_dysautonomia: 6.413% positive rate\n",
      "✅ Train/Test split complete: 71950 train (14390 pos, 57560 neg), 56263 test. Pos rate train=0.200, test=0.065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 14390, number of negative: 57560\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2590\n",
      "[LightGBM] [Info] Number of data points in the train set: 71950, number of used features: 209\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200000 -> initscore=-1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "AUC  : 0.990\n",
      "AUPRC: 0.950\n",
      "Threshold~0.05: Precision=0.594  Recall=0.960\n",
      "Threshold~0.10: Precision=0.739  Recall=0.937\n",
      "Threshold~0.20: Precision=0.824  Recall=0.931\n",
      "✅ Results saved to model_results.csv\n",
      "\n",
      "                                              Y True  \\\n",
      "0  0         0\n",
      "1         0\n",
      "4         0\n",
      "5         ...   \n",
      "\n",
      "                                              Y Prob             Model   AUC  \\\n",
      "0  [0.013003322528135536, 0.007815981896296221, 0...  POTS_Future_LGBM  0.99   \n",
      "\n",
      "   AUPRC  Sensitivity  Specificity  \\\n",
      "0   0.95        0.918        0.992   \n",
      "\n",
      "                                        Top_Features  \n",
      "0  age, cond__inflammatory_arthritis, cond__fibro...  \n",
      "\n",
      "Top 25 features:\n",
      " age                                           10679\n",
      "cond__inflammatory_arthritis                   1239\n",
      "cond__fibromyalgia                             1018\n",
      "cond__migraine_headache                         970\n",
      "cond__eds_hypermobility                         965\n",
      "cond__me_cfs                                    946\n",
      "cond__inflammatory_arthritis__sum_30d           941\n",
      "country_top_US                                  887\n",
      "cond__me_cfs__sum_30d                           803\n",
      "cond__fnd_neurologic_other                      786\n",
      "cond__anxiety                                   768\n",
      "country_top_GB                                  755\n",
      "cond__chronic_pain                              750\n",
      "cond__reflux                                    750\n",
      "cond__acne                                      720\n",
      "cond__acne__sum_30d                             718\n",
      "cond__bp_hypertension_hypotension               696\n",
      "cond__depression                                685\n",
      "cond__fibromyalgia__sum_30d                     668\n",
      "country_top_CA                                  618\n",
      "cond__eds_hypermobility__sum_30d                609\n",
      "cond__ibs                                       588\n",
      "cond__bp_hypertension_hypotension__sum_30d      587\n",
      "cond__migraine_headache__sum_30d                552\n",
      "cond__fnd_neurologic_other__sum_30d             546\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: WHO WILL EVER DEVELOP THE CONDITION =========\n",
    "# Example here is Depression — change target_condition per script.\n",
    "\n",
    "target_condition = \"pots_dysautonomia\"  # <-- CHANGE THIS for each model\n",
    "target_cols = [c for c in daily.columns if c.startswith(f\"cond__{target_condition}\")]\n",
    "if not target_cols:\n",
    "    raise ValueError(f\"No columns found for {target_condition}. Check your keyword mapping!\")\n",
    "\n",
    "# Determine which users ever reported this condition\n",
    "target_users = daily.loc[daily[target_cols].max(axis=1) > 0, \"user_id\"].unique()\n",
    "\n",
    "# Label every record from those users as 1 (ever developed condition), others as 0\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "daily[label_col] = daily[\"user_id\"].isin(target_users).astype(int)\n",
    "\n",
    "print(f\"✅ {label_col}: {daily[label_col].mean():.3%} positive rate\")\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: exclude identifiers & leakage columns\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "leaky_cols = target_cols + [\n",
    "    \"cond__max_severity__mean_30d\",\n",
    "    \"cond__max_severity__mean_7d\", \n",
    "    \"cond__max_severity\"\n",
    "]\n",
    "drop_cols = {\n",
    "    \"user_id\", \"checkin_date\", label_col\n",
    "}.union(leaky_cols)\n",
    "\n",
    "# Features: exclude identifiers & leakage columns\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM (unchanged) =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=None,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"POTS_Future_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d89a7202-359c-4b3e-a019-9632519a9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ label_future_inflammatory_arthritis: 47.534% positive rate\n",
      "✅ Train/Test split complete: 225219 train (108018 pos, 117201 neg), 56263 test. Pos rate train=0.480, test=0.458\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 108018, number of negative: 117201\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2635\n",
      "[LightGBM] [Info] Number of data points in the train set: 225219, number of used features: 210\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.479613 -> initscore=-0.081593\n",
      "[LightGBM] [Info] Start training from score -0.081593\n",
      "AUC  : 0.887\n",
      "AUPRC: 0.867\n",
      "Threshold~0.05: Precision=0.542  Recall=0.987\n",
      "Threshold~0.10: Precision=0.569  Recall=0.975\n",
      "Threshold~0.20: Precision=0.659  Recall=0.922\n",
      "✅ Results saved to model_results.csv\n",
      "\n",
      "                                              Y True  \\\n",
      "0  0         1\n",
      "1         1\n",
      "4         0\n",
      "5         ...   \n",
      "\n",
      "                                              Y Prob           Model    AUC  \\\n",
      "0  [0.2538362286016098, 0.25400719164955626, 0.18...  IA_Future_LGBM  0.887   \n",
      "\n",
      "   AUPRC  Sensitivity  Specificity  \\\n",
      "0  0.867         0.76        0.854   \n",
      "\n",
      "                                        Top_Features  \n",
      "0  age, cond__migraine_headache__sum_30d, cond__m...  \n",
      "\n",
      "Top 25 features:\n",
      " age                                        10003\n",
      "cond__migraine_headache__sum_30d            1285\n",
      "cond__me_cfs__sum_30d                       1239\n",
      "country_top_US                              1201\n",
      "cond__fibromyalgia__sum_30d                 1192\n",
      "cond__chronic_pain__sum_30d                 1094\n",
      "cond__anxiety__sum_30d                      1067\n",
      "cond__depression__sum_30d                    948\n",
      "sex_female                                   908\n",
      "country_top_GB                               886\n",
      "cond__reflux__sum_30d                        778\n",
      "cond__ibs__sum_30d                           772\n",
      "sex_other                                    680\n",
      "country_top_CA                               668\n",
      "sex_male                                     632\n",
      "cond__autoimmune_rheumatologic__sum_30d      630\n",
      "cond__autoimmune_connective__sum_30d         612\n",
      "cond__me_cfs__sum_7d                         594\n",
      "cond__sleep_disorders__sum_30d               576\n",
      "cond__chronic_pain                           569\n",
      "cond__fibromyalgia                           563\n",
      "cond__me_cfs                                 561\n",
      "cond__joint_limb_pain__sum_30d               560\n",
      "cond__fibromyalgia__sum_7d                   558\n",
      "cond__derm_inflammatory__sum_30d             547\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: WHO WILL EVER DEVELOP THE CONDITION =========\n",
    "# (e.g., Epilepsy, POTS, Depression, etc.)\n",
    "\n",
    "# Identify all condition-specific flag columns\n",
    "target_condition = \"inflammatory_arthritis\"  # <-- CHANGE THIS PER MODEL\n",
    "target_cols = [c for c in daily.columns if c.startswith(f\"cond__{target_condition}\")]\n",
    "if not target_cols:\n",
    "    raise ValueError(f\"No columns found for {target_condition}. Check your keyword mapping!\")\n",
    "\n",
    "# Determine which users ever reported the condition\n",
    "target_users = daily.loc[daily[target_cols].max(axis=1) > 0, \"user_id\"].unique()\n",
    "\n",
    "# Label every record from those users as 1 (ever developed condition), others as 0\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "daily[label_col] = daily[\"user_id\"].isin(target_users).astype(int)\n",
    "\n",
    "print(f\"✅ {label_col}: {daily[label_col].mean():.3%} positive rate\")\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "# Build a static per-user table (age/sex/country) at any row; then merge with daily\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "# Keep top 20 countries to control dimensionality\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "# Choose a cutoff date (e.g., last year as test). Adjust to your range.\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: use all engineered columns except identifiers and leakage columns\n",
    "label_col = f\"label_future_{target_condition}\"\n",
    "\n",
    "leaky_cols = target_cols + [\n",
    "    \"cond__max_severity__mean_30d\",\n",
    "    \"cond__max_severity__mean_7d\", \n",
    "    \"cond__max_severity\"\n",
    "]\n",
    "drop_cols = {\n",
    "    \"user_id\", \"checkin_date\", label_col\n",
    "}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# Optional: scale numeric continuous columns (LightGBM doesn’t require it)\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=None,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "# Optional: show precision/recall at a few thresholds\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    # nearest threshold\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"IA_Future_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c742d-109e-4c62-b89e-29d03d895665",
   "metadata": {},
   "source": [
    "### Predicting Next Day Inflammatory Arthritis Flares (Worsening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b48c800a-7c67-46f9-9b11-f5f93ae725ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 15 symptom columns used for flare labeling.\n",
      "✅ Flare labeling complete. Positive rate: 0.078\n",
      "label_nextday_flare\n",
      "0    0.921578\n",
      "1    0.078422\n",
      "Name: proportion, dtype: float64\n",
      "✅ Autoimmune arthritis users identified: 5332\n",
      "✅ Dataset filtered to autoimmune arthritis users only.\n",
      "Remaining records: 99881\n",
      "Flare positive rate: 0.098\n",
      "✅ Train/Test split complete: 38855 train (7771 pos, 31084 neg), 19914 test. Pos rate train=0.200, test=0.102\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 7771, number of negative: 31084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2999\n",
      "[LightGBM] [Info] Number of data points in the train set: 38855, number of used features: 215\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "AUC  : 0.951\n",
      "AUPRC: 0.619\n",
      "Threshold~0.05: Precision=0.347  Recall=0.985\n",
      "Threshold~0.10: Precision=0.391  Recall=0.976\n",
      "Threshold~0.20: Precision=0.427  Recall=0.960\n",
      "✅ Results saved to model_results.csv\n",
      "\n",
      "                                              Y True  \\\n",
      "0  1         0\n",
      "2         0\n",
      "3         0\n",
      "4         ...   \n",
      "\n",
      "                                              Y Prob            Model    AUC  \\\n",
      "0  [0.001722324527153261, 0.006710844408829776, 0...  RA_NextDay_LGBM  0.951   \n",
      "\n",
      "   AUPRC  Sensitivity  Specificity  \\\n",
      "0  0.619        0.894        0.894   \n",
      "\n",
      "                                        Top_Features  \n",
      "0  cond__max_severity__mean_30d, symptom_delta, c...  \n",
      "\n",
      "Top 25 features:\n",
      " cond__max_severity__mean_30d             5652\n",
      "symptom_delta                            4431\n",
      "cond__max_severity__mean_7d              3817\n",
      "age                                      2958\n",
      "cond__chronic_pain__sum_30d              2558\n",
      "cond__inflammatory_arthritis__sum_30d    2430\n",
      "cond__max_severity                       1797\n",
      "cond__joint_limb_pain__sum_30d           1402\n",
      "cond__migraine_headache__sum_30d         1286\n",
      "cond__chronic_pain__sum_7d               1257\n",
      "cond__inflammatory_arthritis__sum_7d     1198\n",
      "cond__back_spine_pain__sum_30d           1090\n",
      "cond__neck_shoulder_pain__sum_30d        1011\n",
      "cond__fibromyalgia__sum_30d               963\n",
      "cond__reflux__sum_30d                     944\n",
      "cond__me_cfs__sum_30d                     928\n",
      "cond__joint_limb_pain__sum_7d             881\n",
      "cond__depression__sum_30d                 844\n",
      "cond__anxiety__sum_30d                    800\n",
      "cond__migraine_headache__sum_7d           657\n",
      "cond__neck_shoulder_pain__sum_7d          624\n",
      "cond__me_cfs__sum_7d                      585\n",
      "cond__back_spine_pain__sum_7d             571\n",
      "cond__joint_limb_pain                     566\n",
      "cond__chronic_pain                        558\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: NEXT-DAY SYMPTOM WORSENING (FLARE) =========\n",
    "import re\n",
    "\n",
    "# 1️⃣ Identify relevant symptom columns\n",
    "sym_cols = [c for c in daily.columns if re.search(r\"(joint|pain|swelling|stiffness)\", c, re.I)]\n",
    "if not sym_cols:\n",
    "    raise ValueError(\"No joint/pain/stiffness symptom columns found. Check your keyword mapping.\")\n",
    "\n",
    "print(f\"✅ Found {len(sym_cols)} symptom columns used for flare labeling.\")\n",
    "\n",
    "# 2️⃣ Compute per-user daily mean across these symptoms\n",
    "daily[\"symptom_pain_mean\"] = daily[sym_cols].mean(axis=1)\n",
    "\n",
    "# 3️⃣ Compute day-to-day change\n",
    "daily[\"symptom_delta\"] = daily.groupby(\"user_id\")[\"symptom_pain_mean\"].diff().fillna(0)\n",
    "\n",
    "# 4️⃣ Define threshold more leniently (for binary data)\n",
    "flare_threshold = 0.1  # or 0.05 if still too strict\n",
    "\n",
    "daily[\"label_nextday_flare\"] = (\n",
    "    daily.groupby(\"user_id\")[\"symptom_delta\"].shift(-1).fillna(0) > flare_threshold\n",
    ").astype(int)\n",
    "\n",
    "# 5️⃣ Require at least two symptom days per user to detect deltas\n",
    "valid_users = daily.groupby(\"user_id\")[\"symptom_pain_mean\"].transform(\"count\") > 1\n",
    "daily = daily[valid_users]\n",
    "\n",
    "# 6️⃣ Optional: require some history\n",
    "daily[\"has_7d_history\"] = daily.groupby(\"user_id\")[\"checkin_date\"].transform(\n",
    "    lambda s: (s - s.min()) >= pd.Timedelta(days=7)\n",
    ")\n",
    "daily = daily[daily[\"has_7d_history\"]]\n",
    "\n",
    "print(\"✅ Flare labeling complete. Positive rate:\",\n",
    "      daily[\"label_nextday_flare\"].mean().round(3))\n",
    "\n",
    "print(daily[\"label_nextday_flare\"].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= FILTER TO AUTOIMMUNE ARTHRITIS USERS =========\n",
    "import re\n",
    "\n",
    "# 1️⃣ Identify inflammatory / autoimmune arthritis condition columns\n",
    "cond_flag_cols = [c for c in daily.columns if c.startswith(\"cond__\")]\n",
    "arth_pattern = re.compile(\n",
    "    r\"(inflammatory[_\\-\\s]*arthritis|rheumatoid[_\\-\\s]*arthritis|psoriatic[_\\-\\s]*arthritis|ankylosing[_\\-\\s]*spondylitis)\",\n",
    "    re.I,\n",
    ")\n",
    "arth_flag_cols = [c for c in cond_flag_cols if arth_pattern.search(c.replace(\"cond__\", \"\"))]\n",
    "\n",
    "if not arth_flag_cols:\n",
    "    raise ValueError(\"No autoimmune arthritis condition columns found in your dataset.\")\n",
    "\n",
    "# 2️⃣ Find users who have ever logged any of these conditions\n",
    "arth_users = daily.loc[daily[arth_flag_cols].sum(axis=1) > 0, \"user_id\"].unique()\n",
    "print(f\"✅ Autoimmune arthritis users identified: {len(arth_users)}\")\n",
    "\n",
    "# 3️⃣ Restrict dataset to only those users\n",
    "daily = daily[daily[\"user_id\"].isin(arth_users)].copy()\n",
    "\n",
    "print(\"✅ Dataset filtered to autoimmune arthritis users only.\")\n",
    "print(\"Remaining records:\", len(daily))\n",
    "print(\"Flare positive rate:\", daily[\"label_nextday_flare\"].mean().round(3))\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: exclude identifiers & leakage columns\n",
    "label_col = \"label_nextday_flare\"\n",
    "\n",
    "leaky_cols = [c for c in daily.columns if \"symptom\" in c and \"pain_mean\" in c]\n",
    "\n",
    "drop_cols = {\"user_id\", \"checkin_date\", \"label_nextday_flare\"}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM (unchanged) =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"RA_NextDay_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013bf6b5-4206-4ba2-a4dd-1f73c764ba75",
   "metadata": {},
   "source": [
    "### Predicting Flares in Epilepsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4ecb48c-f9db-423a-bc68-ea1f14df6672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 0 symptom cluster columns for epilepsy_seizure\n",
      "✅ Epilepsy users identified: 410\n",
      "✅ Dataset filtered to epilepsy users only.\n",
      "Remaining records: 3969\n",
      "Flare positive rate: 0.0\n",
      "✅ Train/Test split complete: 4 train (0 pos, 4 neg), 794 test. Pos rate train=0.000, test=0.000\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Contains only one class\n",
      "[LightGBM] [Info] Number of positive: 0, number of negative: 4\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 4, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 278\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# ========= 11) EVALUATE =========\u001b[39;00m\n\u001b[1;32m    277\u001b[0m p_test \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 278\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, p_test)\n\u001b[1;32m    279\u001b[0m auprc \u001b[38;5;241m=\u001b[39m average_precision_score(y_test, p_test)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:640\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    639\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    641\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    642\u001b[0m         y_true,\n\u001b[1;32m    643\u001b[0m         y_score,\n\u001b[1;32m    644\u001b[0m         average,\n\u001b[1;32m    645\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    649\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    650\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    654\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:382\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n\u001b[1;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: NEXT-DAY FLARE (cluster-based) =========\n",
    "target_condition = \"epilepsy_seizure\"   # or pots / epilepsy / depression\n",
    "\n",
    "# choose cluster sets\n",
    "flare_clusters = {\n",
    "    \"pots_dysautonomia\": [\"fatigue_exhaustion\", \"cardiovascular_symptoms\",\n",
    "             \"lightheaded_dizziness\", \"sleep_symptoms\", \"headache_migraine\"],\n",
    "    \"epilepsy_seizure\": [\"neurologic_other\", \"sleep_symptoms\",\n",
    "                 \"fatigue_exhaustion\", \"cognitive_symptoms\"],\n",
    "    \"anxiety\": [\"anxiety_fear_panic\", \"stress_tension\",\n",
    "                \"sleep_symptoms\", \"cardiovascular_symptoms\"],\n",
    "    \"depression\": [\"negative_affect\", \"fatigue_exhaustion\",\n",
    "                   \"sleep_symptoms\", \"cognitive_symptoms\"]\n",
    "}[target_condition]\n",
    "\n",
    "sym_cols = [c for c in daily.columns\n",
    "            if c.startswith(\"sym__\") and any(k in c for k in flare_clusters)]\n",
    "print(f\"✅ {len(sym_cols)} symptom cluster columns for {target_condition}\")\n",
    "\n",
    "daily[\"symptom_mean\"] = daily[sym_cols].mean(axis=1)\n",
    "daily[\"symptom_delta\"] = daily.groupby(\"user_id\")[\"symptom_mean\"].diff().fillna(0)\n",
    "flare_threshold = 0.1\n",
    "daily[\"label_nextday_flare\"] = (\n",
    "    daily.groupby(\"user_id\")[\"symptom_delta\"].shift(-1).fillna(0) > flare_threshold\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= FILTER TO EPILEPSY USERS =========\n",
    "import re\n",
    "\n",
    "# 1️⃣ Identify condition columns related to epilepsy / seizure disorders\n",
    "cond_flag_cols = [c for c in daily.columns if c.startswith(\"cond__\")]\n",
    "\n",
    "# Pattern matches common epilepsy and seizure cluster names\n",
    "epilepsy_pattern = re.compile(\n",
    "    r\"(epilepsy|seizure|convulsion|temporal[_\\-\\s]*lobe|tonic[_\\-\\s]*clonic|absence[_\\-\\s]*seizure)\",\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "epilepsy_flag_cols = [\n",
    "    c for c in cond_flag_cols if epilepsy_pattern.search(c.replace(\"cond__\", \"\"))\n",
    "]\n",
    "\n",
    "if not epilepsy_flag_cols:\n",
    "    raise ValueError(\"No epilepsy condition columns found in your dataset.\")\n",
    "\n",
    "# 2️⃣ Find users who have ever logged any epilepsy-related conditions\n",
    "epilepsy_users = daily.loc[\n",
    "    daily[epilepsy_flag_cols].sum(axis=1) > 0, \"user_id\"\n",
    "].unique()\n",
    "print(f\"✅ Epilepsy users identified: {len(epilepsy_users)}\")\n",
    "\n",
    "# 3️⃣ Restrict dataset to only those users\n",
    "daily = daily[daily[\"user_id\"].isin(epilepsy_users)].copy()\n",
    "\n",
    "print(\"✅ Dataset filtered to epilepsy users only.\")\n",
    "print(\"Remaining records:\", len(daily))\n",
    "print(\"Flare positive rate:\", daily['label_nextday_flare'].mean().round(3))\n",
    "\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: exclude identifiers & leakage columns\n",
    "label_col = \"label_nextday_flare\"\n",
    "\n",
    "leaky_cols = [c for c in daily.columns if \"symptom\" in c and \"pain_mean\" in c]\n",
    "\n",
    "drop_cols = {\"user_id\", \"checkin_date\", \"label_nextday_flare\"}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM (unchanged) =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"Epi_Flare_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40c493-6025-41d1-b7d1-2c7417868371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: NEXT-DAY FLARE (cluster-based) =========\n",
    "target_condition = \"depression\"   # or pots / epilepsy / depression / anxiety\n",
    "\n",
    "# choose cluster sets\n",
    "flare_clusters = {\n",
    "    \"pots_dysautonomia\": [\"fatigue_exhaustion\", \"cardiovascular_symptoms\",\n",
    "             \"lightheaded_dizziness\", \"sleep_symptoms\", \"headache_migraine\"],\n",
    "    \"epilepsy_seizure\": [\"neurologic_other\", \"sleep_symptoms\",\n",
    "                 \"fatigue_exhaustion\", \"cognitive_symptoms\"],\n",
    "    \"anxiety\": [\"anxiety_fear_panic\", \"stress_tension\",\n",
    "                \"sleep_symptoms\", \"cardiovascular_symptoms\"],\n",
    "    \"depression\": [\"negative_affect\", \"fatigue_exhaustion\",\n",
    "                   \"sleep_symptoms\", \"cognitive_symptoms\"]\n",
    "}[target_condition]\n",
    "\n",
    "sym_cols = [c for c in daily.columns\n",
    "            if c.startswith(\"sym__\") and any(k in c for k in flare_clusters)]\n",
    "print(f\"✅ {len(sym_cols)} symptom cluster columns for {target_condition}\")\n",
    "\n",
    "daily[\"symptom_mean\"] = daily[sym_cols].mean(axis=1)\n",
    "daily[\"symptom_delta\"] = daily.groupby(\"user_id\")[\"symptom_mean\"].diff().fillna(0)\n",
    "flare_threshold = 0.1\n",
    "daily[\"label_nextday_flare\"] = (\n",
    "    daily.groupby(\"user_id\")[\"symptom_delta\"].shift(-1).fillna(0) > flare_threshold\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= FILTER TO DEPRESSION USERS =========\n",
    "import re\n",
    "\n",
    "# 1️⃣ Identify condition columns related to depression or mood disorders\n",
    "cond_flag_cols = [c for c in daily.columns if c.startswith(\"cond__\")]\n",
    "\n",
    "# Pattern matches depression-related cluster names\n",
    "depression_pattern = re.compile(\n",
    "    r\"(depression|depressive|mdd|major[_\\-\\s]*depressive|dysthymia|low[_\\-\\s]*mood)\",\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "depression_flag_cols = [\n",
    "    c for c in cond_flag_cols if depression_pattern.search(c.replace(\"cond__\", \"\"))\n",
    "]\n",
    "\n",
    "if not depression_flag_cols:\n",
    "    raise ValueError(\"No depression condition columns found in your dataset.\")\n",
    "\n",
    "# 2️⃣ Find users who have ever logged any depression-related conditions\n",
    "depression_users = daily.loc[\n",
    "    daily[depression_flag_cols].sum(axis=1) > 0, \"user_id\"\n",
    "].unique()\n",
    "print(f\"✅ Depression users identified: {len(depression_users)}\")\n",
    "\n",
    "# 3️⃣ Restrict dataset to only those users\n",
    "daily = daily[daily[\"user_id\"].isin(depression_users)].copy()\n",
    "\n",
    "print(\"✅ Dataset filtered to depression users only.\")\n",
    "print(\"Remaining records:\", len(daily))\n",
    "print(\"Flare positive rate:\", daily['label_nextday_flare'].mean().round(3))\n",
    "\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: exclude identifiers & leakage columns\n",
    "label_col = \"label_nextday_flare\"\n",
    "\n",
    "leaky_cols = [c for c in daily.columns if \"symptom\" in c and \"pain_mean\" in c]\n",
    "\n",
    "drop_cols = {\"user_id\", \"checkin_date\", \"label_nextday_flare\"}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM (unchanged) =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"Dep_Flare_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a811c-9527-4752-9fb7-c8bfb285a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: NEXT-DAY FLARE (cluster-based) =========\n",
    "target_condition = \"anxiety\"   # or pots / epilepsy / depression / anxiety\n",
    "\n",
    "# choose cluster sets\n",
    "flare_clusters = {\n",
    "    \"pots_dysautonomia\": [\"fatigue_exhaustion\", \"cardiovascular_symptoms\",\n",
    "             \"lightheaded_dizziness\", \"sleep_symptoms\", \"headache_migraine\"],\n",
    "    \"epilepsy_seizure\": [\"neurologic_other\", \"sleep_symptoms\",\n",
    "                 \"fatigue_exhaustion\", \"cognitive_symptoms\"],\n",
    "    \"anxiety\": [\"anxiety_fear_panic\", \"stress_tension\",\n",
    "                \"sleep_symptoms\", \"cardiovascular_symptoms\"],\n",
    "    \"depression\": [\"negative_affect\", \"fatigue_exhaustion\",\n",
    "                   \"sleep_symptoms\", \"cognitive_symptoms\"]\n",
    "}[target_condition]\n",
    "\n",
    "sym_cols = [c for c in daily.columns\n",
    "            if c.startswith(\"sym__\") and any(k in c for k in flare_clusters)]\n",
    "print(f\"✅ {len(sym_cols)} symptom cluster columns for {target_condition}\")\n",
    "\n",
    "daily[\"symptom_mean\"] = daily[sym_cols].mean(axis=1)\n",
    "daily[\"symptom_delta\"] = daily.groupby(\"user_id\")[\"symptom_mean\"].diff().fillna(0)\n",
    "flare_threshold = 0.1\n",
    "daily[\"label_nextday_flare\"] = (\n",
    "    daily.groupby(\"user_id\")[\"symptom_delta\"].shift(-1).fillna(0) > flare_threshold\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= FILTER TO ANXIETY USERS =========\n",
    "import re\n",
    "\n",
    "# 1️⃣ Identify condition columns related to anxiety or panic disorders\n",
    "cond_flag_cols = [c for c in daily.columns if c.startswith(\"cond__\")]\n",
    "\n",
    "# Pattern matches anxiety-related condition cluster names\n",
    "anxiety_pattern = re.compile(\n",
    "    r\"(anxiety|panic|gad|generalized[_\\-\\s]*anxiety|social[_\\-\\s]*anxiety|phobia|ocd|worry)\",\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "anxiety_flag_cols = [\n",
    "    c for c in cond_flag_cols if anxiety_pattern.search(c.replace(\"cond__\", \"\"))\n",
    "]\n",
    "\n",
    "if not anxiety_flag_cols:\n",
    "    raise ValueError(\"No anxiety condition columns found in your dataset.\")\n",
    "\n",
    "# 2️⃣ Find users who have ever logged any anxiety-related conditions\n",
    "anxiety_users = daily.loc[\n",
    "    daily[anxiety_flag_cols].sum(axis=1) > 0, \"user_id\"\n",
    "].unique()\n",
    "print(f\"✅ Anxiety users identified: {len(anxiety_users)}\")\n",
    "\n",
    "# 3️⃣ Restrict dataset to only those users\n",
    "daily = daily[daily[\"user_id\"].isin(anxiety_users)].copy()\n",
    "\n",
    "print(\"✅ Dataset filtered to anxiety users only.\")\n",
    "print(\"Remaining records:\", len(daily))\n",
    "print(\"Flare positive rate:\", daily['label_nextday_flare'].mean().round(3))\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: exclude identifiers & leakage columns\n",
    "label_col = \"label_nextday_flare\"\n",
    "\n",
    "leaky_cols = [c for c in daily.columns if \"symptom\" in c and \"pain_mean\" in c]\n",
    "\n",
    "drop_cols = {\"user_id\", \"checkin_date\", \"label_nextday_flare\"}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM (unchanged) =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"Anx_Flare_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffa488-a814-4f2d-a20e-a4901b9ae35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 1) LOAD & CLEAN =========\n",
    "# Assumes your full long-format table is in df with the columns you listed\n",
    "path = \"/Users/cristybanuelos/Downloads/Chronic_Illness_Dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[df[\"trackable_type\"] == \"Condition\"].copy()\n",
    "df[\"condition_clean\"] = (\n",
    "    df[\"trackable_name\"].str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "# Parse date\n",
    "df[\"checkin_date\"] = pd.to_datetime(df[\"checkin_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"checkin_date\"])  # keep only rows with a date\n",
    "\n",
    "# Basic user-level fields\n",
    "# Age cleaning: clip to a sensible window; set out-of-range to NaN, then impute\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 110), \"age\"] = np.nan  # clip biologically plausible ages\n",
    "df[\"age\"] = df.groupby(\"user_id\")[\"age\"].transform(lambda s: s.fillna(s.median()))\n",
    "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "# Sex cleaning: normalize categories\n",
    "def norm_sex(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in {\"male\", \"m\"}: return \"male\"\n",
    "    if x in {\"female\", \"f\"}: return \"female\"\n",
    "    if x in {\"nan\", \"none\", \"\", \"unknown\"}: return \"unknown\"\n",
    "    return \"other\"\n",
    "df[\"sex\"] = df[\"sex\"].apply(norm_sex)\n",
    "\n",
    "# Country cleaning\n",
    "def norm_country(x):\n",
    "    x = str(x).strip()\n",
    "    return \"unknown\" if (x == \"\" or x.lower() == \"nan\") else x\n",
    "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
    "\n",
    "# ========= 2) TEXT NORMALIZATION (for matching) =========\n",
    "# Create a clean text column for matching on trackable_name\n",
    "df[\"name_clean\"] = (\n",
    "    df[\"trackable_name\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# ========= 3) HELPERS TO FLAG KEYWORDS =========\n",
    "def add_keyword_flags(sub_df, groups_dict, prefix):\n",
    "    \"\"\"\n",
    "    For a subset of df (e.g., only Symptoms, only Food...), add binary columns\n",
    "    indicating whether trackable_name matches any keyword group for that row.\n",
    "    We then aggregate to daily features later.\n",
    "    \"\"\"\n",
    "    out = sub_df.copy()\n",
    "    for group, kws in groups_dict.items():\n",
    "        # Prebuild a regex OR pattern for speed; escape non-alnum safely\n",
    "        pattern = r\"(\" + \"|\".join([re.escape(k.lower()) for k in kws]) + r\")\"\n",
    "        col = f\"{prefix}__{group}\"\n",
    "        out[col] = out[\"name_clean\"].str.contains(pattern, regex=True).astype(int)\n",
    "    return out\n",
    "\n",
    "# ========= 4) PER-TYPE KEYWORD FLAGS =========\n",
    "# NOTE: You already have: keyword_groups (conditions incl. \"epilepsy_seizure\"),\n",
    "#       symptom_keyword_groups, food_keyword_groups, tag_keyword_groups, treatment_keyword_groups\n",
    "\n",
    "# Conditions (Condition rows only)\n",
    "cond_rows = df[df[\"trackable_type\"] == \"Condition\"]\n",
    "cond_rows = add_keyword_flags(cond_rows, condition_keyword_groups, \"cond\")\n",
    "\n",
    "# Symptoms\n",
    "sym_rows = df[df[\"trackable_type\"] == \"Symptom\"]\n",
    "sym_rows = add_keyword_flags(sym_rows, symptom_keyword_groups, \"sym\")\n",
    "\n",
    "# Food\n",
    "food_rows = df[df[\"trackable_type\"] == \"Food\"]\n",
    "food_rows = add_keyword_flags(food_rows, food_keyword_groups, \"food\")\n",
    "\n",
    "# Tags (triggers)\n",
    "tag_rows = df[df[\"trackable_type\"] == \"Tag\"]\n",
    "tag_rows = add_keyword_flags(tag_rows, tag_keyword_groups, \"tag\")\n",
    "\n",
    "# Treatments\n",
    "trt_rows = df[df[\"trackable_type\"] == \"Treatment\"]\n",
    "trt_rows = add_keyword_flags(trt_rows, treatment_keyword_groups, \"trt\")\n",
    "\n",
    "# Weather (already numeric columns; keep as-is if present)\n",
    "weather_rows = df[df[\"trackable_type\"] == \"Weather\"].copy()\n",
    "# Example expected numeric weather columns (adjust to your schema if needed)\n",
    "for col in [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]:\n",
    "    if col in weather_rows.columns:\n",
    "        weather_rows[col] = pd.to_numeric(weather_rows[col], errors=\"coerce\")\n",
    "\n",
    "# ========= 5) DAILY AGGREGATION (no leakage) =========\n",
    "# We build daily features per user, then later roll 7/30d windows that use ONLY past data.\n",
    "\n",
    "def daily_agg_flags(sub, prefix):\n",
    "    # get only the flag columns\n",
    "    flag_cols = [c for c in sub.columns if c.startswith(prefix + \"__\")]\n",
    "    if not flag_cols:\n",
    "        return pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "    # include severity if available (0-4); we’ll take max per day\n",
    "    if \"trackable_value\" in sub.columns:\n",
    "        sub[\"severity_val\"] = pd.to_numeric(sub[\"trackable_value\"], errors=\"coerce\")\n",
    "    else:\n",
    "        sub[\"severity_val\"] = np.nan\n",
    "\n",
    "    agg = (\n",
    "        sub.groupby([\"user_id\", \"checkin_date\"])\n",
    "           .agg({**{c: \"max\" for c in flag_cols}, \"severity_val\": \"max\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    # rename severity\n",
    "    if \"severity_val\" in agg.columns:\n",
    "        agg = agg.rename(columns={\"severity_val\": f\"{prefix}__max_severity\"})\n",
    "    return agg\n",
    "\n",
    "daily_cond = daily_agg_flags(cond_rows,  \"cond\")\n",
    "daily_sym  = daily_agg_flags(sym_rows,   \"sym\")\n",
    "daily_food = daily_agg_flags(food_rows,  \"food\")\n",
    "daily_tag  = daily_agg_flags(tag_rows,   \"tag\")\n",
    "daily_trt  = daily_agg_flags(trt_rows,   \"trt\")\n",
    "\n",
    "# Daily weather (mean if multiple in same day)\n",
    "if not weather_rows.empty:\n",
    "    wcols = [\"temperature_min\", \"temperature_max\", \"precip_intensity\", \"pressure\", \"humidity\"]\n",
    "    wcols = [c for c in wcols if c in weather_rows.columns]\n",
    "    daily_wx = (\n",
    "        weather_rows.groupby([\"user_id\", \"checkin_date\"])[wcols].mean().reset_index()\n",
    "    )\n",
    "else:\n",
    "    daily_wx = pd.DataFrame(columns=[\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# ========= Combine into one daily table =========\n",
    "# Start from all user-day keys present in any table\n",
    "parts = [daily_cond, daily_sym, daily_food, daily_tag, daily_trt, daily_wx]\n",
    "daily = None\n",
    "for p in parts:\n",
    "    if p is None or p.empty: \n",
    "        continue\n",
    "    daily = p if daily is None else pd.merge(daily, p, on=[\"user_id\", \"checkin_date\"], how=\"outer\")\n",
    "\n",
    "if daily is None:\n",
    "    raise ValueError(\"No daily features built. Check your inputs.\")\n",
    "\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"]).reset_index(drop=True)\n",
    "daily = daily.fillna(0)  # for flags; numeric weather stays 0 if missing (fine for tree models)\n",
    "\n",
    "# ========= 6) ROLLING (PAST-ONLY) FEATURES =========\n",
    "# For each user, compute 7d/30d rolling sums of flags + rolling means of severities & weather.\n",
    "def add_rollups(g):\n",
    "    g = g.set_index(\"checkin_date\").sort_index()\n",
    "    # rolling windows (closed='left' to use ONLY past)\n",
    "    win_defs = {\"7d\":\"7D\", \"30d\":\"30D\"}\n",
    "    for col in g.columns:\n",
    "        if col.startswith((\"cond__\", \"sym__\", \"food__\", \"tag__\", \"trt__\")) and col.endswith(\"__max_severity\") is False:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__sum_{k}\"] = g[col].rolling(win, closed=\"left\").sum()\n",
    "        # severities & weather: rolling mean\n",
    "        if col.endswith(\"__max_severity\") or col in [\"temperature_min\",\"temperature_max\",\"precip_intensity\",\"pressure\",\"humidity\"]:\n",
    "            for k, win in win_defs.items():\n",
    "                g[f\"{col}__mean_{k}\"] = g[col].rolling(win, closed=\"left\").mean()\n",
    "    return g.reset_index()\n",
    "\n",
    "daily = daily.groupby(\"user_id\", group_keys=False).apply(add_rollups)\n",
    "# Fill remaining NaNs from leading window edges\n",
    "daily = daily.fillna(0)\n",
    "\n",
    "# ========= 7) BUILD THE TARGET: NEXT-DAY FLARE (cluster-based) =========\n",
    "target_condition = \"pots_dysautonomia\"   # or pots / epilepsy / depression / anxiety\n",
    "\n",
    "# choose cluster sets\n",
    "flare_clusters = {\n",
    "    \"pots_dysautonomia\": [\"fatigue_exhaustion\", \"cardiovascular_symptoms\",\n",
    "             \"lightheaded_dizziness\", \"sleep_symptoms\", \"headache_migraine\"],\n",
    "    \"epilepsy\": [\"neurologic_other\", \"sleep_symptoms\",\n",
    "                 \"fatigue_exhaustion\", \"cognitive_symptoms\"],\n",
    "    \"anxiety\": [\"anxiety_fear_panic\", \"stress_tension\",\n",
    "                \"sleep_symptoms\", \"cardiovascular_symptoms\"],\n",
    "    \"depression\": [\"negative_affect\", \"fatigue_exhaustion\",\n",
    "                   \"sleep_symptoms\", \"cognitive_symptoms\"]\n",
    "}[target_condition]\n",
    "\n",
    "sym_cols = [c for c in daily.columns\n",
    "            if c.startswith(\"sym__\") and any(k in c for k in flare_clusters)]\n",
    "print(f\"✅ {len(sym_cols)} symptom cluster columns for {target_condition}\")\n",
    "\n",
    "daily[\"symptom_mean\"] = daily[sym_cols].mean(axis=1)\n",
    "daily[\"symptom_delta\"] = daily.groupby(\"user_id\")[\"symptom_mean\"].diff().fillna(0)\n",
    "flare_threshold = 0.1\n",
    "daily[\"label_nextday_flare\"] = (\n",
    "    daily.groupby(\"user_id\")[\"symptom_delta\"].shift(-1).fillna(0) > flare_threshold\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# ========= 8) ADD DEMOGRAPHICS (static) =========\n",
    "demo = df.drop_duplicates(\"user_id\")[[\"user_id\",\"age\",\"sex\",\"country\"]].copy()\n",
    "daily = daily.merge(demo, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# One-hot encode sex & country (country can be many; consider top-K and bucket rest as 'other')\n",
    "top_countries = df[\"country\"].value_counts().head(20).index\n",
    "daily[\"country_top\"] = daily[\"country\"].where(daily[\"country\"].isin(top_countries), \"other\")\n",
    "\n",
    "X_cat = pd.get_dummies(daily[[\"sex\",\"country_top\"]], drop_first=False, dtype=int)\n",
    "daily = pd.concat([daily.drop(columns=[\"sex\",\"country\",\"country_top\"]), X_cat], axis=1)\n",
    "\n",
    "# ========= FILTER TO POTS USERS =========\n",
    "import re\n",
    "\n",
    "# 1️⃣ Identify condition columns related to POTS / Dysautonomia\n",
    "cond_flag_cols = [c for c in daily.columns if c.startswith(\"cond__\")]\n",
    "\n",
    "# Pattern matches typical POTS and autonomic dysfunction cluster names\n",
    "pots_pattern = re.compile(\n",
    "    r\"(pots|postural[_\\-\\s]*orthostatic[_\\-\\s]*tachycardia|dysautonomia|autonomic[_\\-\\s]*dysfunction)\",\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "pots_flag_cols = [\n",
    "    c for c in cond_flag_cols if pots_pattern.search(c.replace(\"cond__\", \"\"))\n",
    "]\n",
    "\n",
    "if not pots_flag_cols:\n",
    "    raise ValueError(\"No POTS condition columns found in your dataset.\")\n",
    "\n",
    "# 2️⃣ Find users who have ever logged any POTS-related conditions\n",
    "pots_users = daily.loc[\n",
    "    daily[pots_flag_cols].sum(axis=1) > 0, \"user_id\"\n",
    "].unique()\n",
    "print(f\"✅ POTS users identified: {len(pots_users)}\")\n",
    "\n",
    "# 3️⃣ Restrict dataset to only those users\n",
    "daily = daily[daily[\"user_id\"].isin(pots_users)].copy()\n",
    "\n",
    "print(\"✅ Dataset filtered to POTS users only.\")\n",
    "print(\"Remaining records:\", len(daily))\n",
    "print(\"Flare positive rate:\", daily['label_nextday_flare'].mean().round(3))\n",
    "\n",
    "\n",
    "# ========= 9) TRAIN / TEST TEMPORAL SPLIT =========\n",
    "cutoff = daily[\"checkin_date\"].quantile(0.8)  # 80% oldest for train, 20% most recent for test\n",
    "train = daily[daily[\"checkin_date\"] <= cutoff].copy()\n",
    "test  = daily[daily[\"checkin_date\"] >  cutoff].copy()\n",
    "\n",
    "# Features: exclude identifiers & leakage columns\n",
    "label_col = \"label_nextday_flare\"\n",
    "\n",
    "leaky_cols = [c for c in daily.columns if \"symptom\" in c and \"pain_mean\" in c]\n",
    "\n",
    "drop_cols = {\"user_id\", \"checkin_date\", \"label_nextday_flare\"}.union(leaky_cols)\n",
    "\n",
    "feature_cols = [c for c in daily.columns if c not in drop_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols = make_train_test_balanced(\n",
    "    df=daily,\n",
    "    label_col=label_col,\n",
    "    drop_cols=drop_cols,\n",
    "    pos_to_neg_ratio=4,   # 4:1 neg:pos is usually good\n",
    ")\n",
    "\n",
    "# ========= 10) TRAIN LIGHTGBM (unchanged) =========\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 11) EVALUATE =========\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, p_test)\n",
    "auprc = average_precision_score(y_test, p_test)\n",
    "\n",
    "print(f\"AUC  : {auc:.3f}\")\n",
    "print(f\"AUPRC: {auprc:.3f}\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_test)\n",
    "for t in [0.05, 0.10, 0.20]:\n",
    "    idx = (np.abs(thr - t)).argmin() if len(thr) else -1\n",
    "    if idx >= 0 and idx < len(prec):\n",
    "        print(f\"Threshold~{t:0.2f}: Precision={prec[idx]:.3f}  Recall={rec[idx]:.3f}\")\n",
    "\n",
    "# Evaluate and store results\n",
    "model_name = \"Anx_Flare_LGBM\"  # or \"Epilepsy_30d\", \"RA_NextDay\", etc.\n",
    "evaluate_and_store_results(model_name, y_test, p_test, feature_cols, clf, results_path=\"model_results.csv\")\n",
    "\n",
    "\n",
    "# ========= 12) FEATURE IMPORTANCE =========\n",
    "imp = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(\"\\nTop 25 features:\\n\", imp.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e60d834-1ea0-4c67-a1c4-b3b4743a8e73",
   "metadata": {},
   "source": [
    "---\n",
    "### Modeling Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b63e47-4875-41bb-9792-6f487db5b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "results_df = pd.read_csv(\"model_results.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec529cd-387d-49eb-b44e-db09d4895c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"model_results.csv\")\n",
    "\n",
    "# --- Barplot for AUC & AUPRC --\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(data=results_df.melt(id_vars=\"Model\", value_vars=[\"AUC\", \"AUPRC\"]),\n",
    "            x=\"Model\", y=\"value\", hue=\"variable\")\n",
    "plt.title(\"Model Comparison: AUC and AUPRC\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Sensitivity vs Specificity ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(data=results_df, x=\"Specificity\", y=\"Sensitivity\", hue=\"Model\", s=100)\n",
    "plt.title(\"Sensitivity vs Specificity across Models\")\n",
    "plt.xlim(0, 1); plt.ylim(0, 1)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f0f3b-048e-4527-b444-47f0fdae2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, (p_test >= 0.5).astype(int))\n",
    "plt.title(f\"{model_name} Confusion Matrix\")\n",
    "plt.savefig(f\"plots/{model_name}_confusion.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da55cb-253a-4951-896b-959762e96c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
